---
title: "Vignette Title"
author: "Vignette Author"
date: "`r Sys.Date()`"
output: 
  rmarkdown::pdf_document:
    includes:
      in_header:
        - header.tex
        - highlights.tex
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



\section{Methodology}

- Table mit notation

\subsection{Learning Theory Reminder}

\subsubsection{Loss Function}

The aim of machine learning is to find a model (function) $\hat{f}$ which 
approximate the real but unknown $f$. which best suits our data. But finding 
this model requires a mapping from the training data 
$\mathcal{D}_\mathrm{train} = \left\{(x^{(i)}, y^{(i)})\ |\ i \in \{1, \dots, n\}\right\}$ 
to a model $\hat{f}$. This mapping is called inducer. \\

To quantify the goodness of a prediction $y = f(x)$ we need a function to 
measure the loss of this prediction. Basically, the loss function can also 
be seen as a metric between the true value $y$ and its prediction $y$:

\begin{align*}
  L : \mathcal{Y} \times \mathcal{X} &\rightarrow\ \mathbb{R}_+ \\
                                 y,x &\mapsto\ L\left(y, f(x)\right)
\end{align*}

The loss function is used within the inducer to fit a function (model) 
$\hat{f}$ using training data $\mathcal{D}_\mathrm{train}$ (see section 
\ref{sec:grad-boosting}). It is worth mentioning that different loss functions 
transfer their properties to the inducer. For instance measuring the absolute
difference between $y$ and $f(x)$ (absolute loss) is more robust in terms
of outliers then measuring the qudratic differences (quadratic loss). \\

The properties of the loss function is also used to tackle different tasks. 
Doing classification requires other loss functions than regression tasks. 
To get an overview about different losses and their use see section 
\ref{subsec:loss-classes} about the implemented loss classes of 
\texttt{compboost}.


\subsubsection{Empirical Risk}

It would be desirable to have the loss for every possible combination of 
$x \in \mathcal{X}$ and the corresponding true value $y \in \mathcal{Y}$. 
Therefore, the natural thing would be to measure the expectation of the loss
with respect to the joint distribution $\mathbb{P}_{xy}$. This expectation is
defined as the risk $\mathcal{R}(f)$:
\[
  \mathcal{R}(f) = \mathbb{E}\left[L(y, f(x))\right] = \int L(y,f(x))\ d\mathbb{P}_{xy}
\]

Since $\mathbb{P}_{xy}$ is unknown it is not possible to exactly calculate 
$\mathcal{R}(f)$. The most common way to approximate the risk is to use its
empirical analogon the mean using the observation of the training data 
$(y, x) \in \mathcal{D}_\mathrm{train}$. This is called the empirical risk
$\mathcal{R}_\mathrm{emp}(f)$:
\[
  \mathcal{R}_\mathrm{emp}(f) = \frac{1}{n}\sum\limits_{i=1}^n\ 
  L\left(y^{(i)}, f(x^{(i)})\right)
\]

It is also common to use the empirical risk as a summed version:
\[
  \mathcal{R}_\mathrm{emp}(f) = \sum\limits_{i=1}^n\ 
  L\left(y^{(i)}, f(x^{(i)})\right)
\]

In \texttt{compboost} we are using the average version of the empirical risk.\\

\subsubsection{Loss Minimization}

An obvious aim is now to minimize the empirical risk which is also known as
loss minimization and use the function $\hat{f}$ which minimizes 
$\mathcal{R}_\mathrm{emp}(f)$:
\[
  \hat{f} = \underset{f \in H}{\mathrm{arg~min}}\ \mathcal{R}_\mathrm{emp}(f)
\]

In component-wise boosting we assume that $f$ is a function which can be 
parameterized by $\theta \in \Theta$ since we want to have interpretable 
learner (as we will see later). Hence, we can parameterize the empirical risk:
\[
  \mathcal{R}_\mathrm{emp}(\theta) = \frac{1}{n}\sum\limits_{i=1}^n\ 
  L\left(y^{(i)}, f(x^{(i)}|\theta)\right)
\]
Therefore, the loss minimization yields in finding a parameter setting  
$\hat{\theta}$ which minimizes $\mathcal{R}_\mathrm{emp}(\theta)$:
\[
  \hat{\theta} = \underset{\theta \in \Theta}{\mathrm{arg~min}}\
  \mathcal{R}_\mathrm{emp}(\theta)
\]


\subsection{Gradient Boosting Reminder}\label{sec:grad-boosting}

\subsubsection{Forward Stagewise Additive Modelling}

Generally, boosting fits an additive model \cite[p.~341]{friedman2001elements}.
This means, that we can fit $f$ in an additive fashion
\[
  f(x) = \sum\limits_{m=1}^M \beta{[m]}b\left(x,\theta^{[m]}\right)
\]
where $\beta^{[m]}$, $m = 1, \dots, M$ are the expansion coefficients and 
$b(x, \theta) \in \mathbb{R}$ are so-called basis functions of the input $x$
specified by the parameters $\theta$. \\

Having $f(x)$ our goal is now to minimize $\mathcal{R}_\mathrm{emp}$ using 
this additive structure:
\[
  \mathcal{R}_\mathrm{emp}(f) = \frac{1}{n}\sum\limits_{i=1}^n L\left(y^{(i)}, f(x^{(i)})\right)  =
  \frac{1}{n}\sum\limits_{i=1}^n L\left(y^{(i)},\ \sum\limits_{m=1}^M \beta^{[m]}b\left(x,\theta^{[m]}\right)\right)
\]
We notice, that we can parameterize $f$ by introducing a parameter vector  
$\theta_0$ containing all parameter:
\[
  \theta_0 = \left(\left(\beta^{[1]}, \theta^{[1]}\right), \dots, \left(\beta^{[M]}, \theta^{[M]}\right) \right)
\]
Hence, we want to minimize $\mathcal{R}_\mathrm{emp}(\theta_0) = \mathcal{R}_\mathrm{emp}(f)$
with respect to $\theta_0$. However, the dimension of $\theta_0$ can be very
big which makes it difficult to find $\hat{\theta}_0$.\\


As \cite[p.~342]{friedman2001elements} have pointed out, \enquote{\textit{
forward stagewise additive modeling approximate the solution by sequentially 
adding new basis functions to the expansion without adjusting the parameters and 
coefficients of those that have already been added.}} This procedure is 
shown in Algorithm \ref{algo:forw-stage-add-mod}.

\begin{Shaded}
\begin{algorithm}[H]
Initialize $\hat{f}^{[0]} = 0$\;\vspace{0.2cm}
\For{$m \in \{1, \dots, M\}$}{\vspace{0.2cm}
  // Fit $m$-th baselearner: \\
  $\left(\hat{\beta}^{[m]},\ \hat{\theta}^{[m]}\right) = \underset{\beta, \theta}{\mathrm{arg~min}}\ \frac{1}{n}\sum\limits_{i=1}^n\ L\left(y^{(i)},\ \hat{f}^{[m-1]}(x^{(i)}) + \beta b\left(x,\theta\right)\right)$ \;\vspace{0.2cm}
  // Update $\hat{f}$: \\
  $\hat{f}^{[m]}(x) = \hat{f}^{[m-1]}(x) + \hat{\beta}^{[m]}b(x,\hat{\theta}^{[m]})$ \;\vspace{0.2cm}
 }
\caption{Forward stagewise additive modeling.}\label{algo:forw-stage-add-mod}
\end{algorithm}
\end{Shaded}

The takeaway of forward stagewise additive modelling is the idea of 
sequentially cumulating weak learner to a more powerful learner. Next we
want to introduce gradient boosting as a model class which utilise this 
strategy.

\subsubsection{Gradient Boosting}

A very popular algorithm for binary classification called AdaBoost was 
introduced by \cite{freund1997decision}. The concept of gradient boosting is
a generalization of AdaBoost and can be motivated by approximate the unknown 
function $f$ via optimizing in function space. We also have already seen, 
that for forward additive stagewise modeling we have to optimize the empirical 
risk with respect to the newest base function at iteration $m$. Now, to find
the new additive base learner $b(x,\theta^{[m]})$ we use gradient descent in
function space.\\

The overall goal is to find a function $f$ which minimize the empirical Risk 
$\mathcal{R}_\mathrm{emp}$. Therefore we use
gradient descent with $f$ as \enquote{parameter}:
\[
  f^{[m+1]}(x) = f^{[m]}(x) - \beta^{[m]}\left[\frac{\delta}{\delta f(x)} \mathcal{R}_\mathrm{emp}(f)\right]_{f = f^{[m]}}
\]
Next, we imagine the respone $y \in \mathbb{R}^n$



- Ganz kurz boosting (eher zitieren)



\subsection{Component-wise Boosting}


- Bisschen genauer model based boosting
- Verweis auf implementierte baselearner in classes